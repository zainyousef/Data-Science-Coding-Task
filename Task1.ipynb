{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataGrasp Coding Test - Task 1 \n",
    "### Zain Yousef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ignore": true
   },
   "outputs": [],
   "source": [
    "library(ISLR, quietly = TRUE)\n",
    "library(tidyverse, quietly = TRUE)\n",
    "library(dplyr, quietly = TRUE)\n",
    "library(caret, quietly = TRUE)\n",
    "library(MASS, quietly = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Stock Market Data & Initial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ignore": true
   },
   "outputs": [],
   "source": [
    "Smarket = Smarket # import data\n",
    "levels(Smarket$Direction) = c(\"Up\", \"Down\") #relevel Direction\n",
    "\n",
    "#dim(Smarket) # rows columns\n",
    "\n",
    "#summary(Smarket) # summary of variables\n",
    "\n",
    "#cor(Smarket) # Error in cor(Smarket) : 'x' must be numeric\n",
    "#cor(Smarket[,-9]) #remove column 9 and display correlations\n",
    "\n",
    "#pairs(Smarket) # scatterplot matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Split data into train & test\n",
    "Split the dataset into training and testing parts. \n",
    "Generate training (before year 2005) and testing (on year 2005) datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = filter(Smarket, Year < 2005)\n",
    "test = filter(Smarket, Year >= 2005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Logistic Regression \n",
    "\n",
    "#### i) Fit a generalized linear regression to the training dataset using a logit link function, set distribution of the response variable to be binomial. Regress direction on Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 correct predictions out of 252"
     ]
    }
   ],
   "source": [
    "mod = glm(Direction~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data = train, family = binomial(link = \"logit\"))\n",
    "\n",
    "predictions = predict(mod,newdata =  test, type = \"response\") # Predicts values using glm model\n",
    "\n",
    "predictions = # Classifies predicted values as Up (>= 0.5) or Down (< 0.5)\n",
    "  predictions %>% \n",
    "  as.data.frame() %>%\n",
    "  mutate(predictions = ifelse(predictions >= 0.5, \"Up\",\"Down\"))\n",
    "\n",
    "test_w_predicted = cbind(test, \"predictions\" = predictions$predictions) #add predicted values to test dataset\n",
    "\n",
    "test_w_predicted = # New column calculating whether prediction correct or incorrect\n",
    "  test_w_predicted %>%\n",
    "  mutate(`Correct Prediction` = ifelse(Direction == predictions, 1,0)) \n",
    "cat(paste(sum(test_w_predicted$`Correct Prediction`), \"correct predictions out of\", nrow(test_w_predicted) ))\n",
    "\n",
    "levels(test_w_predicted$Direction) = c(\"Up\", \"Down\") #relevel Direction variable\n",
    "levels(test_w_predicted$predictions) = c(\"Up\", \"Down\") #relevel Prediction variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  ii) Compute the confusion matrix of the outcome of testing data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction Up Down\n",
       "      Up   77   97\n",
       "      Down 34   44\n",
       "                                         \n",
       "               Accuracy : 0.4802         \n",
       "                 95% CI : (0.417, 0.5437)\n",
       "    No Information Rate : 0.5595         \n",
       "    P-Value [Acc > NIR] : 0.9952         \n",
       "                                         \n",
       "                  Kappa : 0.0054         \n",
       "                                         \n",
       " Mcnemar's Test P-Value : 6.062e-08      \n",
       "                                         \n",
       "            Sensitivity : 0.6937         \n",
       "            Specificity : 0.3121         \n",
       "         Pos Pred Value : 0.4425         \n",
       "         Neg Pred Value : 0.5641         \n",
       "             Prevalence : 0.4405         \n",
       "         Detection Rate : 0.3056         \n",
       "   Detection Prevalence : 0.6905         \n",
       "      Balanced Accuracy : 0.5029         \n",
       "                                         \n",
       "       'Positive' Class : Up             \n",
       "                                         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusionMatrix(test_w_predicted$predictions, reference = test_w_predicted$Direction, \"Up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Linear Discriminant Analysis\n",
    "\n",
    "#### i) Perform LDA on the training data set using only two predictors, 1st lag and 2nd lag \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.mod = lda(Direction~ Lag1 + Lag2, data = train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii) Compute the confusion matrix of the outcome of testing data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "          Reference\n",
       "Prediction  Up Down\n",
       "      Up    35   35\n",
       "      Down  76  106\n",
       "                                          \n",
       "               Accuracy : 0.5595          \n",
       "                 95% CI : (0.4959, 0.6218)\n",
       "    No Information Rate : 0.5595          \n",
       "    P-Value [Acc > NIR] : 0.5262856       \n",
       "                                          \n",
       "                  Kappa : 0.0698          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.0001467       \n",
       "                                          \n",
       "            Sensitivity : 0.3153          \n",
       "            Specificity : 0.7518          \n",
       "         Pos Pred Value : 0.5000          \n",
       "         Neg Pred Value : 0.5824          \n",
       "             Prevalence : 0.4405          \n",
       "         Detection Rate : 0.1389          \n",
       "   Detection Prevalence : 0.2778          \n",
       "      Balanced Accuracy : 0.5335          \n",
       "                                          \n",
       "       'Positive' Class : Up              \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict.lda = predict(lda.mod, newdata = test)\n",
    "confusionMatrix(predict.lda$class, test$Direction, positive = \"Up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Comparison\n",
    "\n",
    "#### i) Compare the two methods above and state the limitations and advantages of both methods \n",
    "\n",
    "- The overall accuracy of the LDA model (0.5595) is greater than the accuracy of the Logistic Regression model (0.4802) and therefore the LDA model is more accurate predictor for Sales (up/ down). \n",
    "- The LDA model has a higher accuracy rate for predicting both Up and Down outcomes. \n",
    "- LDA works under the assumption that the explanatory variables are normally distributed and therefore will perform better than a Logistic Regression model when the data is normally distributed. This advantage of LDA is also a limitation as it is only effective when the explanatory variables are normally distributed. \n",
    "- Below you can see that by plotting histograms for all of the explanatory variables they all suggest they follow a normal distrubution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nVObme355mAAAAABJRU5ErkJggg==",
      "text/plain": [
       "Plot with title \"Volume\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "par(mfrow = c(2,3))\n",
    "for(i in 2:7){hist(Smarket[,i], main = names(Smarket)[i], xlab = names(Smarket)[i])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Therefore explaining why the LDA model has a higher accuracy than the Logistic regression model in this scenario.\n",
    "- Logistic regression models are not reliant on constant variance as well as normality of explanatory variables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
